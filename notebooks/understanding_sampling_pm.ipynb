{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook is for taking a closer look into the effects of new observations\n",
    "(possibly fantasy observations) on the posterior mean and variance. It is intended more\n",
    " as a sanity check, to help with better understanding the behavior of lookahead PCS.\n",
    "\n",
    "Let's start with SingleTaskGP. This will be representative for independent arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.test_functions import Branin\n",
    "from gpytorch import ExactMarginalLogLikelihood\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([55.1395, 51.9170, 48.6181, 45.5666, 42.6158, 39.6841, 36.7813, 33.7308,\n",
      "        30.9662, 28.7889], grad_fn=<ViewBackward>)\n",
      "variance: tensor([0.3276, 0.2162, 0.2026, 0.2000, 0.1997, 0.1997, 0.2000, 0.2027, 0.2161,\n",
      "        0.3276], grad_fn=<ViewBackward>)\n",
      "fm mean: tensor([[55.2837, 51.9466, 48.6078, 45.5620, 42.6173, 39.6851, 36.7811, 33.7306,\n",
      "         30.9663, 28.7890],\n",
      "        [55.3597, 51.9623, 48.6023, 45.5596, 42.6181, 39.6857, 36.7810, 33.7304,\n",
      "         30.9663, 28.7890],\n",
      "        [54.9628, 51.8808, 48.6307, 45.5722, 42.6139, 39.6827, 36.7814, 33.7310,\n",
      "         30.9663, 28.7889],\n",
      "        [55.0856, 51.9060, 48.6219, 45.5683, 42.6152, 39.6836, 36.7812, 33.7308,\n",
      "         30.9662, 28.7889]], grad_fn=<ViewBackward>)\n",
      "fm variance: tensor([[0.2526, 0.2130, 0.2023, 0.2000, 0.1998, 0.1997, 0.2001, 0.2027, 0.2162,\n",
      "         0.3276],\n",
      "        [0.2526, 0.2130, 0.2023, 0.2000, 0.1998, 0.1997, 0.2001, 0.2027, 0.2162,\n",
      "         0.3276],\n",
      "        [0.2526, 0.2130, 0.2023, 0.2000, 0.1998, 0.1997, 0.2001, 0.2027, 0.2162,\n",
      "         0.3276],\n",
      "        [0.2526, 0.2130, 0.2023, 0.2000, 0.1998, 0.1997, 0.2001, 0.2027, 0.2162,\n",
      "         0.3276]], grad_fn=<ViewBackward>)\n",
      "mean diff: tensor([[-1.4428e-01, -2.9617e-02,  1.0357e-02,  4.5700e-03, -1.5259e-03,\n",
      "         -9.9182e-04,  1.1063e-04,  2.0218e-04, -4.0054e-05, -5.3406e-05],\n",
      "        [-2.2023e-01, -4.5246e-02,  1.5877e-02,  6.9695e-03, -2.2545e-03,\n",
      "         -1.6022e-03,  2.1362e-04,  3.9291e-04, -3.6240e-05, -8.5831e-05],\n",
      "        [ 1.7662e-01,  3.6217e-02, -1.2596e-02, -5.6572e-03,  1.8806e-03,\n",
      "          1.3428e-03, -1.2970e-04, -2.3651e-04, -3.2425e-05,  4.7684e-05],\n",
      "        [ 5.3867e-02,  1.1017e-02, -3.7689e-03, -1.7815e-03,  5.9509e-04,\n",
      "          4.3488e-04,  4.5776e-05,  7.6294e-06,  9.5367e-06,  1.9073e-06]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "variance diff: tensor([[ 7.5019e-02,  3.2291e-03,  3.7989e-04, -4.5225e-05, -9.9495e-05,\n",
      "          4.5225e-05, -1.0855e-04,  3.6180e-05, -3.6195e-05, -4.5240e-05],\n",
      "        [ 7.5019e-02,  3.2291e-03,  3.7989e-04, -4.5225e-05, -9.0450e-05,\n",
      "          5.4270e-05, -1.0855e-04,  3.6180e-05, -3.6195e-05, -4.5240e-05],\n",
      "        [ 7.5019e-02,  3.2291e-03,  3.7989e-04, -4.5225e-05, -9.9495e-05,\n",
      "          4.5225e-05, -1.0855e-04,  3.6180e-05, -3.6195e-05, -4.5240e-05],\n",
      "        [ 7.5019e-02,  3.2291e-03,  3.7989e-04, -4.5225e-05, -9.0450e-05,\n",
      "          5.4270e-05, -1.0855e-04,  3.6180e-05, -3.6195e-05, -4.5240e-05]],\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.linspace(0, 1, 20).view(-1, 2).repeat(3, 1)\n",
    "test_func = Branin()\n",
    "train_Y = Branin(noise_std=1.0)(train_X).view(-1, 1)\n",
    "model = SingleTaskGP(\n",
    "    train_X, train_Y, outcome_transform=Standardize(m=1)\n",
    ")\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "posterior = model.posterior(train_X[:10])\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "\n",
    "fm = model.fantasize(train_X[0].view(1, 1, 2), SobolQMCNormalSampler(4))\n",
    "fm_posterior = fm.posterior(train_X[:10])\n",
    "fm_mean = fm_posterior.mean\n",
    "fm_variance = fm_posterior.variance\n",
    "\n",
    "print(f\"mean: {mean.view(-1)}\")\n",
    "print(f\"variance: {variance.view(-1)}\")\n",
    "\n",
    "print(f\"fm mean: {fm_mean.view(4, 10)}\")\n",
    "print(f\"fm variance: {fm_variance.view(4, 10)}\")\n",
    "\n",
    "print(f\"mean diff: {(mean - fm_mean).view(4, 10)}\")\n",
    "print(f\"variance diff: {(variance - fm_variance).view(4, 10)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}