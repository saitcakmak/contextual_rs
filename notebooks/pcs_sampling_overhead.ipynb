{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook is to have a rough idea of how much of an improvement there's to gain\n",
    "from coming up with a Li type approximation to PCS.\n",
    "\n",
    "Li takes advantage of IID normal structure to easily come up with an estimate based on\n",
    "the volume of a sphere. If we were to attempt a similar idea, we would be dealing with\n",
    "ellipses and Cholesky factors.\n",
    "\n",
    "Need to take a more careful look into what is necessary to get such an approximation,\n",
    "but let's start with comparing the time to draw a single sample vs multiple samples\n",
    "using the empirical PCS code. It is possible that by avoiding sorting of many samples,\n",
    "we would gain significant computational savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import resource\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch import ExactMarginalLogLikelihood\n",
    "from torch import Tensor\n",
    "from contextual_rs.models.lce_gp import LCEGP\n",
    "from contextual_rs.generalized_pcs import estimate_current_generalized_pcs\n",
    "\n",
    "ckwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "\n",
    "def clock2():\n",
    "    \"\"\"\n",
    "    clock2() -> (t_user,t_system)\n",
    "    Return a tuple of user/system cpu times.\n",
    "    \"\"\"\n",
    "    return resource.getrusage(resource.RUSAGE_SELF)[:2]\n",
    "\n",
    "\n",
    "def sine_test(X: Tensor) -> Tensor:\n",
    "    return torch.sin(X * 10.0).sum(dim=-1, keepdim=True)\n",
    "\n",
    "# running a simple test with LCEGP\n",
    "# test with LCEMGP\n",
    "dim_x = 1\n",
    "context_dim = 2\n",
    "num_arms = 6\n",
    "num_contexts = 10\n",
    "num_full_train = 3\n",
    "arm_set = torch.arange(0, num_arms, **ckwargs).view(-1, 1)\n",
    "context_map = torch.rand(num_contexts, context_dim, **ckwargs)\n",
    "train_X = (\n",
    "    torch.cat(\n",
    "        [\n",
    "            arm_set.view(-1, 1, 1).expand(-1, num_contexts, -1),\n",
    "            context_map.expand(num_arms, -1, -1),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    .view(-1, context_dim + 1)\n",
    "    .repeat(num_full_train, 1)\n",
    ")\n",
    "# construct and train the model\n",
    "model = LCEGP(\n",
    "    train_X, sine_test(train_X), categorical_cols=[0]\n",
    ")\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "def estimate_w_samples(\n",
    "    num_samples: int, replications: int,\n",
    "):\n",
    "    wall_times = torch.zeros(replications, **ckwargs)\n",
    "    user_cts = torch.zeros(replications, **ckwargs)\n",
    "    sys_cts = torch.zeros(replications, **ckwargs)\n",
    "    for seed in range(replications):\n",
    "        # clean caches\n",
    "        model.train()\n",
    "        model.eval()\n",
    "        torch.manual_seed(seed)\n",
    "        # start times\n",
    "        wt_start = time.time()\n",
    "        ct_start = clock2()\n",
    "        # run\n",
    "        estimate_current_generalized_pcs(\n",
    "            model=model,\n",
    "            arm_set=arm_set,\n",
    "            context_set=context_map,\n",
    "            num_samples=num_samples,\n",
    "            base_samples=None,\n",
    "            func_I=lambda X: (X > 0).to(**ckwargs),\n",
    "            rho=lambda X: X.mean(dim=-2),\n",
    "        )\n",
    "        # record times\n",
    "        ct_end = clock2()\n",
    "        wt_end = time.time()\n",
    "        wall_times[seed] = wt_end - wt_start\n",
    "        user_cts[seed] = ct_end[0] - ct_start[0]\n",
    "        sys_cts[seed] = ct_end[1] - ct_start[1]\n",
    "    return (\n",
    "        wall_times.mean(),\n",
    "        user_cts.mean(),\n",
    "        sys_cts.mean(),\n",
    "        user_cts.mean() + sys_cts.mean()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples 1\n",
      "peak memory: 280.56 MiB, increment: 16.58 MiB\n",
      "Wall time 0.008, user time 0.038, sys time 0.001, total cpu time 0.039\n",
      "Num samples 16\n",
      "peak memory: 290.91 MiB, increment: 11.72 MiB\n",
      "Wall time 0.008, user time 0.036, sys time 0.000, total cpu time 0.036\n",
      "Num samples 64\n",
      "peak memory: 300.08 MiB, increment: 9.16 MiB\n",
      "Wall time 0.008, user time 0.038, sys time 0.001, total cpu time 0.039\n",
      "Num samples 256\n",
      "peak memory: 310.19 MiB, increment: 11.34 MiB\n",
      "Wall time 0.008, user time 0.045, sys time 0.001, total cpu time 0.046\n",
      "Num samples 1024\n",
      "peak memory: 323.76 MiB, increment: 14.73 MiB\n",
      "Wall time 0.010, user time 0.052, sys time 0.002, total cpu time 0.054\n",
      "Num samples 16384\n",
      "peak memory: 396.96 MiB, increment: 73.20 MiB\n",
      "Wall time 0.041, user time 0.109, sys time 0.003, total cpu time 0.112\n"
     ]
    }
   ],
   "source": [
    "for num_samples in [1, 16, 64, 256, 1024, 2**14 ]:\n",
    "    print(f\"Num samples {num_samples}\")\n",
    "    %memit times = estimate_w_samples(num_samples, 1000)\n",
    "    print(\n",
    "        f\"Wall time {'{:.3f}'.format(float(times[0]))}, \"\n",
    "        f\"user time {'{:.3f}'.format(float(times[1]))}, \"\n",
    "        f\"sys time {'{:.3f}'.format(float(times[2]))}, \"\n",
    "        f\"total cpu time {'{:.3f}'.format(float(times[3]))}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These timings are a little suspicious. I'd expect the difference to be larger.\n",
    "\n",
    "So, let's bisect the method and measure purely the sampling time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# generate the tensor of arm-context pairs\n",
    "arm_context_pairs = torch.cat(\n",
    "    [\n",
    "        arm_set.unsqueeze(-2).expand(-1, context_map.shape[0], -1),\n",
    "        context_map.expand(arm_set.shape[0], -1, -1),\n",
    "    ],\n",
    "    dim=-1,\n",
    ").reshape(num_arms * num_contexts, -1)\n",
    "\n",
    "\n",
    "def estimate_w_samples_only(\n",
    "    num_samples: int, replications: int,\n",
    "):\n",
    "    wall_times = torch.zeros(replications, **ckwargs)\n",
    "    user_cts = torch.zeros(replications, **ckwargs)\n",
    "    sys_cts = torch.zeros(replications, **ckwargs)\n",
    "    for seed in range(replications):\n",
    "        # clean caches\n",
    "        model.train()\n",
    "        model.eval()\n",
    "        torch.manual_seed(seed)\n",
    "        # start times\n",
    "        wt_start = time.time()\n",
    "        ct_start = clock2()\n",
    "        # run\n",
    "        posterior = model.posterior(arm_context_pairs)\n",
    "        y_samples = posterior.rsample(\n",
    "            sample_shape=torch.Size([num_samples])\n",
    "        )\n",
    "        # record times\n",
    "        ct_end = clock2()\n",
    "        wt_end = time.time()\n",
    "        wall_times[seed] = wt_end - wt_start\n",
    "        user_cts[seed] = ct_end[0] - ct_start[0]\n",
    "        sys_cts[seed] = ct_end[1] - ct_start[1]\n",
    "    return (\n",
    "        wall_times.mean(),\n",
    "        user_cts.mean(),\n",
    "        sys_cts.mean(),\n",
    "        user_cts.mean() + sys_cts.mean()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples 1\n",
      "peak memory: 390.88 MiB, increment: 7.62 MiB\n",
      "Wall time 0.007, user time 0.034, sys time 0.001, total cpu time 0.034\n",
      "Num samples 16\n",
      "peak memory: 399.79 MiB, increment: 8.77 MiB\n",
      "Wall time 0.007, user time 0.035, sys time 0.001, total cpu time 0.035\n",
      "Num samples 64\n",
      "peak memory: 408.81 MiB, increment: 8.93 MiB\n",
      "Wall time 0.007, user time 0.034, sys time 0.001, total cpu time 0.034\n",
      "Num samples 256\n",
      "peak memory: 417.70 MiB, increment: 8.89 MiB\n",
      "Wall time 0.008, user time 0.042, sys time 0.001, total cpu time 0.043\n",
      "Num samples 1024\n",
      "peak memory: 426.74 MiB, increment: 8.98 MiB\n",
      "Wall time 0.009, user time 0.048, sys time 0.001, total cpu time 0.048\n",
      "Num samples 16384\n",
      "peak memory: 500.28 MiB, increment: 73.54 MiB\n",
      "Wall time 0.038, user time 0.099, sys time 0.003, total cpu time 0.103\n"
     ]
    }
   ],
   "source": [
    "for num_samples in [1, 16, 64, 256, 1024, 2**14 ]:\n",
    "    print(f\"Num samples {num_samples}\")\n",
    "    %memit times = estimate_w_samples_only(num_samples, 1000)\n",
    "    print(\n",
    "        f\"Wall time {'{:.3f}'.format(float(times[0]))}, \"\n",
    "        f\"user time {'{:.3f}'.format(float(times[1]))}, \"\n",
    "        f\"sys time {'{:.3f}'.format(float(times[2]))}, \"\n",
    "        f\"total cpu time {'{:.3f}'.format(float(times[3]))}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}