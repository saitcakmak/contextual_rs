{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we want to see how Adam and LBFGS compare when fitting LCEGP. We also\n",
    "want to play around with the number of iterations allowed to see how that affects things.\n",
    "\n",
    "The question is how to compare the fit alternatives??\n",
    "We could check the MLL values - it is a flawed metric but better than nothing.\n",
    "\"\n",
    "Use optimizer_kwargs = {\"options\": {\"maxiter\": maxiter_}} to limit number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.optim.fit import fit_gpytorch_scipy, fit_gpytorch_torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch import ExactMarginalLogLikelihood\n",
    "\n",
    "from contextual_rs.models.lce_gp import LCEGP\n",
    "\n",
    "ckwargs = {\"device\": \"cpu\", \"dtype\": torch.float}\n",
    "\n",
    "def fit_baseline_gp(\n",
    "    num_train: int,\n",
    "    dim: int,\n",
    ") -> SingleTaskGP:\n",
    "    train_X = torch.rand(num_train, dim, **ckwargs)\n",
    "    train_Y = torch.randn(num_train, 1, **ckwargs)\n",
    "    model = SingleTaskGP(train_X, train_Y)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_on_baselines(\n",
    "    d_cont: int,\n",
    "    num_cat: int,\n",
    "    num_cont: int,\n",
    "    num_baseline_train: int,\n",
    "    replications: int,\n",
    "    optimizer: Callable,\n",
    "    optimizer_kwargs: dict,\n",
    "):\n",
    "    all_mlls = torch.zeros(replications, **ckwargs)\n",
    "    iters = torch.zeros(replications, **ckwargs)\n",
    "    for seed in range(replications):\n",
    "        torch.manual_seed(seed)\n",
    "        baseline = fit_baseline_gp(num_baseline_train, d_cont+1)\n",
    "        cats = torch.arange(0, num_cat, **ckwargs).view(num_cat, 1)\n",
    "        train_X = torch.cat(\n",
    "            [\n",
    "                cats.view(-1, 1, 1).expand(-1, num_cont, -1),\n",
    "                torch.rand(num_cat, num_cont, d_cont, **ckwargs)\n",
    "            ], dim=-1\n",
    "        )\n",
    "        train_X_eval = train_X.clone()\n",
    "        train_X_eval[..., 0] = train_X_eval[..., 0] / num_cat\n",
    "        with torch.no_grad():\n",
    "            train_Y = baseline.posterior(train_X_eval).mean\n",
    "        model = LCEGP(train_X, train_Y, [0])\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        mll, info_dict = optimizer(mll, track_iterations=True, **optimizer_kwargs)\n",
    "        all_mlls[seed] = info_dict[\"fopt\"]\n",
    "        iters[seed] = len(info_dict[\"iterations\"])\n",
    "    return all_mlls, iters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's just run a simple test first."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mlls: tensor([26.4275, 26.1508, 26.8268])\n",
      "Adam mlls: tensor([26.9916, 28.1221, 28.3788])\n",
      "LBFGS iters: tensor([58., 53., 60.])\n",
      "Adam iters: tensor([50., 39., 39.])\n"
     ]
    }
   ],
   "source": [
    "lbfgs_mlls, lbfgs_iters = fit_on_baselines(\n",
    "    d_cont=2,\n",
    "    num_cat=6,\n",
    "    num_cont=10,\n",
    "    num_baseline_train=20,\n",
    "    replications=3,\n",
    "    optimizer=fit_gpytorch_scipy,\n",
    "    optimizer_kwargs=dict()\n",
    ")\n",
    "\n",
    "adam_mlls, adam_iters = fit_on_baselines(\n",
    "    d_cont=2,\n",
    "    num_cat=6,\n",
    "    num_cont=10,\n",
    "    num_baseline_train=20,\n",
    "    replications=3,\n",
    "    optimizer=fit_gpytorch_torch,\n",
    "    optimizer_kwargs={\"options\": {\"disp\": False}}\n",
    ")\n",
    "\n",
    "print(f\"LBFGS mlls: {lbfgs_mlls}\")\n",
    "print(f\"Adam mlls: {adam_mlls}\")\n",
    "print(f\"LBFGS iters: {lbfgs_iters}\")\n",
    "print(f\"Adam iters: {adam_iters}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 2,\n",
    "    \"num_cat\": 6,\n",
    "    \"num_cont\": 10,\n",
    "    \"num_baseline_train\": 20,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 26.39801025390625, std: 0.5533416867256165\n",
      "LBFGS iters, avg: 79.76667022705078, std: 32.117977142333984\n",
      "CPU times: user 2min 46s, sys: 595 ms, total: 2min 47s\n",
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 27.490205764770508, std: 0.6860774755477905\n",
      "Adam iters, avg: 47.70000076293945, std: 14.960062026977539\n",
      "CPU times: user 54.3 s, sys: 197 ms, total: 54.5 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 2,\n",
    "    \"num_cat\": 10,\n",
    "    \"num_cont\": 10,\n",
    "    \"num_baseline_train\": 30,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 66.84286499023438, std: 0.4117429256439209\n",
      "LBFGS iters, avg: 30.233333587646484, std: 5.49409294128418\n",
      "CPU times: user 1min 27s, sys: 295 ms, total: 1min 27s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 67.77068328857422, std: 1.0745059251785278\n",
      "Adam iters, avg: 91.86666870117188, std: 21.090499877929688\n",
      "CPU times: user 1min 31s, sys: 271 ms, total: 1min 31s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 1,\n",
    "    \"num_cat\": 10,\n",
    "    \"num_cont\": 20,\n",
    "    \"num_baseline_train\": 20,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 17.527326583862305, std: 3.4920310974121094\n",
      "LBFGS iters, avg: 15.366666793823242, std: 5.162753582000732\n",
      "CPU times: user 1min 6s, sys: 1.45 s, total: 1min 7s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 17.032188415527344, std: 2.3136327266693115\n",
      "Adam iters, avg: 65.5999984741211, std: 13.745469093322754\n",
      "CPU times: user 1min 2s, sys: 1.29 s, total: 1min 3s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 4,\n",
    "    \"num_cat\": 10,\n",
    "    \"num_cont\": 20,\n",
    "    \"num_baseline_train\": 20,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 35.880760192871094, std: 0.2730153799057007\n",
      "LBFGS iters, avg: 47.266666412353516, std: 8.08546257019043\n",
      "CPU times: user 1min 57s, sys: 2.34 s, total: 1min 59s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 35.91973876953125, std: 0.2560601532459259\n",
      "Adam iters, avg: 99.69999694824219, std: 1.6431676149368286\n",
      "CPU times: user 1min 40s, sys: 2.08 s, total: 1min 42s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 4,\n",
    "    \"num_cat\": 5,\n",
    "    \"num_cont\": 20,\n",
    "    \"num_baseline_train\": 40,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 9.431946754455566, std: 1.287776231765747\n",
      "LBFGS iters, avg: 166.56666564941406, std: 156.10842895507812\n",
      "CPU times: user 5min 27s, sys: 1.12 s, total: 5min 29s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 11.157636642456055, std: 0.22094941139221191\n",
      "Adam iters, avg: 52.766666412353516, std: 4.538595676422119\n",
      "CPU times: user 1min 7s, sys: 240 ms, total: 1min 7s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 2,\n",
    "    \"num_cat\": 5,\n",
    "    \"num_cont\": 20,\n",
    "    \"num_baseline_train\": 30,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 6.512121200561523, std: 2.445747137069702\n",
      "LBFGS iters, avg: 55.0, std: 44.02742004394531\n",
      "CPU times: user 2min 29s, sys: 436 ms, total: 2min 29s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 10.719143867492676, std: 0.4961346983909607\n",
      "Adam iters, avg: 44.70000076293945, std: 1.0221680402755737\n",
      "CPU times: user 57 s, sys: 253 ms, total: 57.2 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"d_cont\": 1,\n",
    "    \"num_cat\": 5,\n",
    "    \"num_cont\": 10,\n",
    "    \"num_baseline_train\": 25,\n",
    "    \"replications\": 30,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS mll, avg: 13.640057563781738, std: 1.6636030673980713\n",
      "LBFGS iters, avg: 24.96666717529297, std: 12.890743255615234\n",
      "CPU times: user 1min 15s, sys: 229 ms, total: 1min 16s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_scipy, optimizer_kwargs=dict(), **kwargs\n",
    ")\n",
    "print(f\"LBFGS mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"LBFGS iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 14.872940063476562, std: 1.8696917295455933\n",
      "Adam iters, avg: 56.66666793823242, std: 10.927135467529297\n",
      "CPU times: user 55.3 s, sys: 123 ms, total: 55.4 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch, optimizer_kwargs={\"options\": {\"disp\": False}}, **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 14.93786907196045, std: 1.8196450471878052\n",
      "Adam iters, avg: 49.13333511352539, std: 1.1665846109390259\n",
      "CPU times: user 48.3 s, sys: 170 ms, total: 48.5 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch,\n",
    "    optimizer_kwargs={\"options\": {\"disp\": False, \"maxiter\": 50}},\n",
    "    **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam mll, avg: 21.671274185180664, std: 0.2634010314941406\n",
      "Adam iters, avg: 25.0, std: 0.0\n",
      "CPU times: user 33 s, sys: 95.2 ms, total: 33.1 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlls, iters = fit_on_baselines(\n",
    "    optimizer=fit_gpytorch_torch,\n",
    "    optimizer_kwargs={\"options\": {\"disp\": False, \"maxiter\": 25}},\n",
    "    **kwargs\n",
    ")\n",
    "print(f\"Adam mll, avg: {mlls.mean()}, std: {mlls.std()}\")\n",
    "print(f\"Adam iters, avg: {iters.mean()}, std: {iters.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}