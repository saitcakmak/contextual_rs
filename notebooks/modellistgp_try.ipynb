{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook is for playing around with ModelListGP to understand how it can be used\n",
    "to model each arm independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.models import ModelListGP, SingleTaskGP\n",
    "from gpytorch import ExactMarginalLogLikelihood\n",
    "\n",
    "mlgp = ModelListGP(\n",
    "    SingleTaskGP(torch.rand(10, 2), torch.randn(10, 1)),\n",
    "    SingleTaskGP(torch.rand(20, 2), torch.randn(20, 1)),\n",
    "    SingleTaskGP(torch.rand(30, 2), torch.randn(30, 1)),\n",
    "    SingleTaskGP(torch.rand(15, 2), torch.randn(15, 1)),\n",
    "    SingleTaskGP(torch.rand(50, 2), torch.randn(50, 1))\n",
    ")\n",
    "for model in mlgp.models:\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "test_X = torch.rand(4, 2)\n",
    "\n",
    "posterior = mlgp.posterior(test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2621, -0.0446,  0.0125, -0.9178, -0.1116],\n        [-0.5756, -0.0809, -0.1007,  1.3870,  0.0771],\n        [-0.5253, -0.0190, -0.0712,  1.3117,  0.1402],\n        [ 0.6169, -0.2835, -0.1900,  0.9450, -0.1993]],\n       grad_fn=<CopyBackwards>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior.mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.2991,  0.1191,  0.1332,  0.0010,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.1191,  0.2156,  0.1735,  0.0110,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.1332,  0.1735,  0.1948,  0.0027,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0010,  0.0110,  0.0027,  0.1538,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1597,  0.0477,  0.0582,  0.0031,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0477,  0.1176,  0.1128,  0.0405,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0582,  0.1128,  0.1175,  0.0264,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0031,  0.0405,  0.0264,  0.1341,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.1114,  0.0548,  0.0624,  0.0109,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0548,  0.1149,  0.1112,  0.0490,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0624,  0.1112,  0.1149,  0.0359,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0109,  0.0490,  0.0359,  0.1294,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.4578, -0.0063, -0.0019, -0.0066,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000, -0.0063,  0.2684,  0.2564,  0.0854,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000, -0.0019,  0.2564,  0.3071,  0.0039,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000, -0.0066,  0.0854,  0.0039,  0.8547,\n          0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.1260,  0.0492,  0.0562,  0.0050],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0492,  0.1065,  0.0987,  0.0316],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0562,  0.0987,  0.1013,  0.0186],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0050,  0.0316,  0.0186,  0.1261]], grad_fn=<MatmulBackward>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior.mvn.covariance_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, it essentially stitches together the outputs from multiple models.\n",
    "\n",
    "An important question here is \"Does this stitching together come with a performance\n",
    "penalty?\"\n",
    "\n",
    "Let's try to time this quickly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saitcakmak/anaconda3/envs/contextual_rs/lib/python3.8/site-packages/gpytorch/utils/cholesky.py:51: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLGP sampling took 2.7713494300842285\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10):\n",
    "    test_X = torch.rand(1000, 2)\n",
    "    posterior = mlgp.posterior(test_X)\n",
    "    samples = posterior.rsample(torch.Size([1000]))\n",
    "\n",
    "print(f\"MLGP sampling took {time()-start}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saitcakmak/anaconda3/envs/contextual_rs/lib/python3.8/site-packages/gpytorch/utils/cholesky.py:51: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual sampling took 2.908242702484131\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10):\n",
    "    test_X = torch.rand(1000, 2)\n",
    "    for model in mlgp.models:\n",
    "        posterior = model.posterior(test_X)\n",
    "        samples = posterior.rsample(torch.Size([1000]))\n",
    "\n",
    "print(f\"Individual sampling took {time()-start}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Everything looks ok, there doesn't seem to be any penalty for using this directly.\n",
    "\n",
    "The next step is to make IKG work with MLGP. This is being done under `finite_ikg` code."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}